{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "from neural_rk.hyperparameter import get_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = get_hp(\n",
    "    [\n",
    "        # ----------------- Data -----------------\n",
    "        \"--equation=heat\",\n",
    "        \"--data=A\",\n",
    "        # \"--noise=0.0000\",\n",
    "        # \"--take_only=0.5\",\n",
    "        # \"--window=1\",\n",
    "        # ------------------ NN ------------------\n",
    "        \"--rk=RK1\",\n",
    "        # \"--approximator_in_scaler=sincos\",\n",
    "        # \"--approximator_out_scaler=minmax\",\n",
    "        \"--approximator_state_embedding\", \"32\",\n",
    "        # \"--approximator_node_embedding\", \"32\",\n",
    "        \"--approximator_edge_embedding\", \"32\",\n",
    "        # \"--approximator_glob_embedding\", \"8\",\n",
    "        \"--approximator_edge_hidden=128\",\n",
    "        \"--approximator_node_hidden=128\",\n",
    "        # \"--approximator_dropout=0.0\",\n",
    "        # \"--approximator_bn_momentum=-1.0\",\n",
    "        # ---------- Loss and Optimizer ----------\n",
    "        # \"--loss=MSE\",\n",
    "        # \"--optimizer=AdamW\",\n",
    "        # \"--weight_decay=0.0\",\n",
    "        # --------------- Schedular --------------\n",
    "        \"--scheduler_name=cosine\",\n",
    "        \"--scheduler_lr=0.0001\",\n",
    "        \"--scheduler_lr_max=1e-2\",\n",
    "        \"--scheduler_lr_max_mult=0.7\",\n",
    "        \"--scheduler_period=10\",\n",
    "        \"--scheduler_period_mult=2.0\",\n",
    "        \"--scheduler_warmup=0\",\n",
    "        # -------------- Early Stop --------------\n",
    "        # \"--earlystop_patience=60\",\n",
    "        # \"--earlystop_delta=0.0\",\n",
    "        # ------------ Train config --------------\n",
    "        # \"--resume=qctrttyx\",\n",
    "        \"--device\", \"0\", \"1\", \"2\", \"3\",\n",
    "        # \"--device\", \"0\",\n",
    "        # \"--seed=0\",\n",
    "        # \"--port=3184\",\n",
    "        \"--epochs=310\",\n",
    "        \"--batch_size=256\",\n",
    "        # \"--rollout_batch_size=16\",\n",
    "        \"--tqdm\",\n",
    "        \"--wandb\",\n",
    "        \"--amp\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data took 0.24762598425149918 seconds\n",
      "Creating model took 0.019394150003790855 seconds\n",
      "Start running experiment heat_pd4za4zd \n",
      "Number of trainable parameters : 27745 \n",
      "Number of train data: 20000            \n",
      "Number of validation data: 2000        \n",
      "Number of rollout data: 20             \n",
      "Best model at epoch=0                  \n",
      "Best model at epoch=1                          \n",
      "Best model at epoch=2                          \n",
      "Best model at epoch=3                          \n",
      "Best model at epoch=4                          \n",
      "Best model at epoch=5                          \n",
      "Best model at epoch=6                          \n",
      "Best model at epoch=7                          \n",
      "Best model at epoch=8                          \n",
      "Best model at epoch=9                          \n",
      "Best model at epoch=14                          \n",
      "Best model at epoch=15                          \n",
      "Best model at epoch=16                          \n",
      "Best model at epoch=17                          \n",
      "Best model at epoch=18                          \n",
      "Best model at epoch=19                          \n",
      "Best model at epoch=20                          \n",
      "Best model at epoch=21                          \n",
      "Best model at epoch=22                          \n",
      "Best model at epoch=23                          \n",
      "Best model at epoch=25                          \n",
      "Best model at epoch=27                          \n",
      "Best model at epoch=28                          \n",
      "Best model at epoch=40                          \n",
      "Best model at epoch=41                          \n",
      "Best model at epoch=45                          \n",
      "Best model at epoch=46                          \n",
      "Best model at epoch=47                          \n",
      "Best model at epoch=48                          \n",
      "Best model at epoch=49                          \n",
      "Best model at epoch=50                          \n",
      "Best model at epoch=51                          \n",
      "Best model at epoch=55                          \n",
      "Best model at epoch=57                          \n",
      "Best model at epoch=58                          \n",
      "Best model at epoch=59                          \n",
      "Best model at epoch=60                          \n",
      "Best model at epoch=61                          \n",
      "Best model at epoch=62                          \n",
      "Best model at epoch=63                          \n",
      "Best model at epoch=94                          \n",
      "Best model at epoch=95                          \n",
      "Best model at epoch=98                          \n",
      "Best model at epoch=99                          \n",
      "Best model at epoch=107                          \n",
      "Best model at epoch=109                          \n",
      "Best model at epoch=111                          \n",
      "Best model at epoch=113                          \n",
      "Best model at epoch=116                          \n",
      "Best model at epoch=119                          \n",
      "Best model at epoch=120                          \n",
      "Best model at epoch=121                          \n",
      "Best model at epoch=123                          \n",
      "Best model at epoch=125                          \n",
      "Best model at epoch=127                          \n",
      "Best model at epoch=128                          \n",
      "Best model at epoch=131                          \n",
      "Best model at epoch=134                          \n",
      "Best model at epoch=135                          \n",
      "Best model at epoch=136                          \n",
      "Best model at epoch=138                          \n",
      "Best model at epoch=139                          \n",
      "Best model at epoch=142                          \n",
      "Best model at epoch=143                          \n",
      "Best model at epoch=144                          \n",
      "Best model at epoch=149                          \n",
      "Best model at epoch=186                          \n",
      "Best model at epoch=188                          \n",
      "Best model at epoch=190                          \n",
      "Best model at epoch=191                          \n",
      "Best model at epoch=192                          \n",
      "Best model at epoch=193                          \n",
      "Best model at epoch=194                          \n",
      "Best model at epoch=195                          \n",
      "Best model at epoch=196                          \n",
      "Best model at epoch=197                          \n",
      "Best model at epoch=200                          \n",
      "Best model at epoch=201                          \n",
      "Best model at epoch=203                          \n",
      "Best model at epoch=206                          \n",
      "Best model at epoch=207                          \n",
      "Best model at epoch=210                          \n",
      "Best model at epoch=211                          \n",
      "Best model at epoch=212                          \n",
      "Best model at epoch=215                          \n",
      "Best model at epoch=217                          \n",
      "Best model at epoch=219                          \n",
      "Best model at epoch=220                          \n",
      "Best model at epoch=221                          \n",
      "Best model at epoch=225                          \n",
      "Best model at epoch=229                          \n",
      "Best model at epoch=231                          \n",
      "Best model at epoch=232                          \n",
      "Best model at epoch=234                          \n",
      "Best model at epoch=236                          \n",
      "Best model at epoch=237                          \n",
      "Best model at epoch=238                          \n",
      "Best model at epoch=239                          \n",
      "Best model at epoch=241                          \n",
      "Best model at epoch=242                          \n",
      "Best model at epoch=245                          \n",
      "Best model at epoch=247                          \n",
      "Best model at epoch=248                          \n",
      "Best model at epoch=252                          \n",
      "Best model at epoch=253                          \n",
      "Best model at epoch=255                          \n",
      "Best model at epoch=258                          \n",
      "Best model at epoch=259                          \n",
      "Best model at epoch=261                          \n",
      "Best model at epoch=263                          \n",
      "Best model at epoch=266                          \n",
      "Best model at epoch=267                          \n",
      "Best model at epoch=270                          \n",
      "Best model at epoch=272                          \n",
      "Best model at epoch=275                          \n",
      "Best model at epoch=276                          \n",
      "Best model at epoch=277                          \n",
      "Best model at epoch=278                          \n",
      "Best model at epoch=280                          \n",
      "Best model at epoch=281                          \n",
      "Best model at epoch=283                          \n",
      "Best model at epoch=284                          \n",
      "Best model at epoch=286                          \n",
      "Best model at epoch=288                          \n",
      "Best model at epoch=289                          \n",
      "Best model at epoch=291                          \n",
      "Best model at epoch=292                          \n",
      "Best model at epoch=294                          \n",
      "Best model at epoch=296                          \n",
      "Best model at epoch=297                          \n",
      "Best model at epoch=298                          \n",
      "Best model at epoch=299                          \n",
      "Best model at epoch=300                          \n",
      "Best model at epoch=301                          \n",
      "Best model at epoch=302                          \n",
      "Best model at epoch=303                          \n",
      "Best model at epoch=304                          \n",
      "Best model at epoch=305                          \n",
      "Best model at epoch=307                          \n",
      "Best model at epoch=308                          \n",
      "100%|██████████| 310/310 [10:31<00:00,  2.04s/it]\n",
      "Training took 665.451772974804 seconds\n"
     ]
    }
   ],
   "source": [
    "main(hp, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
