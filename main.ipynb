{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "from neural_rk.hyperparameter import get_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = get_hp(\n",
    "    [\n",
    "        # ----------------- Data -----------------\n",
    "        \"--equation=rossler\",\n",
    "        \"--data=A\",\n",
    "        \"--noise=0.0000\",\n",
    "        \"--take_only=1.0\",\n",
    "        \"--window=1\",\n",
    "        # ------------------ NN ------------------\n",
    "        \"--rk=RK1\",\n",
    "        # \"--approximator_in_scaler=sincos\",\n",
    "        # \"--approximator_out_scaler=minmax\",\n",
    "        \"--approximator_state_embedding\", \"32\",\n",
    "        # \"--approximator_node_embedding\", \"32\",\n",
    "        \"--approximator_edge_embedding\", \"32\",\n",
    "        \"--approximator_glob_embedding\", \"32\",\n",
    "        \"--approximator_edge_hidden=128\",\n",
    "        \"--approximator_node_hidden=128\",\n",
    "        # \"--approximator_dropout=0.0\",\n",
    "        # \"--approximator_bn_momentum=1.0\",\n",
    "        # ---------- Loss and Optimizer ----------\n",
    "        # \"--loss=MSE\",\n",
    "        # \"--optimizer=AdamW\",\n",
    "        # \"--weight_decay=0.0\",\n",
    "        # --------------- Schedular --------------\n",
    "        \"--scheduler_name=cosine\",\n",
    "        \"--scheduler_lr=1e-5\",\n",
    "        \"--scheduler_lr_max=2e-3\",\n",
    "        \"--scheduler_lr_max_mult=0.6\",\n",
    "        \"--scheduler_period=20\",\n",
    "        \"--scheduler_period_mult=1.4\",\n",
    "        \"--scheduler_warmup=0\",\n",
    "        # -------------- Early Stop --------------\n",
    "        # \"--earlystop_patience=60\",\n",
    "        # \"--earlystop_delta=0.0\",\n",
    "        # ------------ Train config --------------\n",
    "        # \"--resume=qctrttyx\",\n",
    "        \"--device\", \"0\", \"1\", \"2\", \"3\",\n",
    "        # \"--device\", \"0\",\n",
    "        # \"--seed=0\",\n",
    "        # \"--port=3184\",\n",
    "        \"--epochs=979\",\n",
    "        \"--batch_size=128\",\n",
    "        # \"--rollout_batch_size=16\",\n",
    "        \"--tqdm\",\n",
    "        \"--wandb\",\n",
    "        \"--amp\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data took 0.5283288138452917 seconds\n",
      "Creating model took 0.2828860869631171 seconds\n",
      "Start running experiment rossler_qctrttyx\n",
      "Number of trainable parameters : 79267 \n",
      "Number of train data: 400000           \n",
      "Number of validation data: 40000       \n",
      "Number of rollout data: 20             \n",
      "Best model at epoch=0                  \n",
      "Best model at epoch=2                            \n",
      "Best model at epoch=3                            \n",
      "Best model at epoch=5                            \n",
      "Best model at epoch=6                            \n",
      "Best model at epoch=9                            \n",
      "Best model at epoch=12                            \n",
      "Best model at epoch=13                            \n",
      "Best model at epoch=15                            \n",
      "Best model at epoch=17                            \n",
      "Best model at epoch=68                            \n",
      "Best model at epoch=74                            \n",
      "Best model at epoch=80                            \n",
      "Best model at epoch=83                            \n",
      "Best model at epoch=86                            \n",
      "Best model at epoch=93                              \n",
      "Best model at epoch=114                              \n",
      "Best model at epoch=118                              \n",
      "Best model at epoch=121                              \n",
      "Best model at epoch=134                              \n",
      "Best model at epoch=136                            \n",
      "Best model at epoch=139                            \n",
      "Best model at epoch=141                            \n",
      "Best model at epoch=146                            \n",
      "Best model at epoch=149                            \n",
      "Best model at epoch=150                            \n",
      "Best model at epoch=153                            \n",
      "Best model at epoch=154                            \n",
      "Best model at epoch=155                            \n",
      "Best model at epoch=158                            \n",
      "Best model at epoch=159                            \n",
      "Best model at epoch=161                            \n",
      "Best model at epoch=163                            \n",
      "Best model at epoch=164                            \n",
      "Best model at epoch=168                            \n",
      "Best model at epoch=170                            \n",
      "Best model at epoch=172                            \n",
      "Best model at epoch=173                            \n",
      "Best model at epoch=177                            \n",
      "Best model at epoch=182                            \n",
      "Best model at epoch=186                            \n",
      "Best model at epoch=187                            \n",
      "Best model at epoch=188                            \n",
      "Best model at epoch=190                            \n",
      "Best model at epoch=194                            \n",
      "Best model at epoch=200                            \n",
      "Best model at epoch=202                            \n",
      "Best model at epoch=205                            \n",
      "Best model at epoch=207                            \n",
      "Best model at epoch=216                            \n",
      "100%|██████████| 217/217 [2:19:09<00:00, 38.48s/it]\n",
      "Training took 8413.652450137073 seconds\n"
     ]
    }
   ],
   "source": [
    "main(hp, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
